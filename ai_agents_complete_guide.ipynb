{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Agents ‚Äî Complete Guide\n",
    "\n",
    "This notebook provides a comprehensive learning resource for AI Agents, covering 80 topics with detailed explanations, decision-making frameworks (when/why to use), and complete working code examples.\n",
    "\n",
    "## Table of Contents: 80 AI Agent Topics\n",
    "\n",
    "### Part 1 ‚Äî Agent Fundamentals (6 topics)\n",
    "1. What are AI Agents?\n",
    "2. Agent Architectures (Reactive, Deliberative, Hybrid)\n",
    "3. Agent Components (Perception, Planning, Action, Memory)\n",
    "4. Types of Agents (Goal-based, Utility-based, Learning agents)\n",
    "5. Environment Types (deterministic/stochastic, episodic/sequential)\n",
    "6. Agent Lifecycle & Event Loops\n",
    "\n",
    "### Part 2 ‚Äî Architectures & Patterns (6 topics)\n",
    "7. Reactive Agents / Behavior-based\n",
    "8. Deliberative (Planning) Agents\n",
    "9. Hybrid Architectures (Sense-Plan-Act + Reactive)\n",
    "10. Modular Agent Design\n",
    "11. Agent-Oriented Programming\n",
    "12. Agent Communication Patterns\n",
    "\n",
    "### Part 3 ‚Äî Reasoning & Planning (6 topics)\n",
    "13. Symbolic Planning (PDDL, STRIPS)\n",
    "14. Heuristic Search (A*, Best-First)\n",
    "15. Task & Motion Planning\n",
    "16. Probabilistic Planning (POMDPs)\n",
    "17. Hierarchical Task Networks (HTN)\n",
    "18. Real-time Planning & Replanning\n",
    "\n",
    "### Part 4 ‚Äî Learning & Adaptation (6 topics)\n",
    "19. Reinforcement Learning agents\n",
    "20. Imitation Learning & Behavioral Cloning\n",
    "21. Offline RL vs Online RL\n",
    "22. Meta-learning for agents\n",
    "23. Continual Learning for Agents\n",
    "24. Multi-task & Transfer Learning\n",
    "\n",
    "### Part 5 ‚Äî Language-Capable Agents (6 topics)\n",
    "25. LLM-based Agents (Planner/Executor)\n",
    "26. ReAct & Thought-Action loops\n",
    "27. Tool-Enabled Agents (APIs, Search, Databases)\n",
    "28. Agents with Retrieval (RAG + agents)\n",
    "29. Conversational Agents and Dialog Management\n",
    "30. Safety & Alignment for LLM Agents\n",
    "\n",
    "### Part 6 ‚Äî Tools & Integrations (6 topics)\n",
    "31. Tool design patterns (idempotent, side-effect control)\n",
    "32. Tool authorization & sandboxing\n",
    "33. Tool orchestration & workflows\n",
    "34. Observability & tool-level logging\n",
    "35. External knowledge sources (APIs, KB, DBs)\n",
    "36. Agent testing & sandboxing strategies\n",
    "\n",
    "### Part 7 ‚Äî Memory & State Management (6 topics)\n",
    "37. Short-term vs Long-term memory\n",
    "38. Vector memory & embeddings for agents\n",
    "39. Memory retrieval strategies (LRU, recency+relevance)\n",
    "40. Memory condensation & summarization\n",
    "41. Privacy & retention policies for memory\n",
    "42. Grounding memory with sources & citations\n",
    "\n",
    "### Part 8 ‚Äî Multi-Agent Systems (6 topics)\n",
    "43. Coordination & Negotiation\n",
    "44. Emergent behavior in MAS\n",
    "45. Communication protocols and ACLs\n",
    "46. Distributed planning & consensus\n",
    "47. Market-based & auction mechanisms\n",
    "48. Safety in multi-agent contexts\n",
    "\n",
    "### Part 9 ‚Äî Evaluation & Metrics (6 topics)\n",
    "49. Task success metrics & rewards\n",
    "50. Efficiency metrics (latency, cost)\n",
    "51. Groundedness & hallucination rate\n",
    "52. Human preference & UX metrics\n",
    "53. Robustness to distribution shift\n",
    "54. Interpretability & auditability\n",
    "\n",
    "### Part 10 ‚Äî Safety, Ethics & Governance (6 topics)\n",
    "55. Safety layers (validators, simulators)\n",
    "56. Ethical considerations (bias, fairness)\n",
    "57. Governance and access control\n",
    "58. Red-team testing for agents\n",
    "59. Fail-safe & graceful degradation\n",
    "60. Consent & user control over agents\n",
    "\n",
    "### Part 11 ‚Äî Deployment & Scaling (6 topics)\n",
    "61. Edge vs Cloud agents\n",
    "62. Autoscaling agent services\n",
    "63. Caching & partial result reuse\n",
    "64. Monitoring & alerting for agents\n",
    "65. Cost-optimization strategies\n",
    "66. Versioning & rollbacks for agent policies\n",
    "\n",
    "### Part 12 ‚Äî Advanced Patterns (6 topics)\n",
    "67. Agent-of-Agents / Meta-agents\n",
    "68. Self-reflective agents (self-debugging)\n",
    "69. Curriculum learning for agents\n",
    "70. Human-in-the-loop & escalation policies\n",
    "71. Hybrid symbolic-LLM agents\n",
    "72. Agents for complex simulations\n",
    "\n",
    "### Part 13 ‚Äî Frameworks & Tooling (8 topics)\n",
    "73. LangChain agents patterns\n",
    "74. AutoGen / Colang / Taskmatrix tools\n",
    "75. Microsoft/Anthropic/OpenAI agent SDKs\n",
    "76. Benchmarks & agent eval toolkits\n",
    "77. Debugging agents (traces, replays)\n",
    "78. Security tools & policy enforcement\n",
    "79. Example reference projects & templates\n",
    "80. Future directions & research challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269774f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Topic 1 ‚Äî What are AI Agents?\n",
    "\n",
    "### Definition\n",
    "An AI agent is a software entity that:\n",
    "- **Perceives** its environment (sensors, inputs, API responses, user queries)\n",
    "- **Maintains state** (memory, internal models, conversation history)\n",
    "- **Reasons or plans** what to do next (symbolic planners, RL policies, LLM-based reasoning)\n",
    "- **Acts** to achieve goals (calls tools, APIs, writes outputs, updates databases)\n",
    "- **Learns** and adapts over time (optional, but often valuable)\n",
    "\n",
    "### Core Components\n",
    "1. **Perception Layer**: Sensors, API clients, event listeners, input parsing\n",
    "2. **Memory**: Short-term (current context), long-term (history, learned patterns)\n",
    "3. **Reasoning/Planning Engine**: Decides next action (rule-based, heuristic search, LLM, RL policy)\n",
    "4. **Tool Executor**: Runs tools, APIs, handles side effects safely\n",
    "5. **Tools/Actuators**: External capabilities (web search, calculator, database, API calls, file I/O)\n",
    "\n",
    "### Why Use AI Agents?\n",
    "‚úÖ **Automate multi-step workflows**: Chain tool calls together (search ‚Üí summarize ‚Üí email)  \n",
    "‚úÖ **Complex reasoning**: Decompose tasks, plan sequences, adapt to errors  \n",
    "‚úÖ **Maintain context**: Remember history, manage conversation state  \n",
    "‚úÖ **Safe external tool access**: Control what tools agents can call, audit all actions  \n",
    "‚úÖ **Scalable orchestration**: Coordinate multiple systems (APIs, databases, services)  \n",
    "‚úÖ **Error recovery**: Agents can retry, backtrack, or escalate when stuck  \n",
    "\n",
    "### When NOT to Use Agents\n",
    "‚ùå Simple single-turn queries (direct LLM call is faster)  \n",
    "‚ùå Real-time latency-critical systems (<100ms response required)  \n",
    "‚ùå No external tool access needed (overhead of orchestration not justified)  \n",
    "‚ùå Fully deterministic logic (traditional software is simpler, auditable)  \n",
    "‚ùå Highly sensitive operations without proven safety (use with caution or on-premise only)  \n",
    "\n",
    "### Key Risks & Mitigations\n",
    "| Risk | Mitigation |\n",
    "|------|-----------|\n",
    "| Hallucinations | Use retrieval, tool verification, validators |\n",
    "| Untrusted tool calls | Sandbox tools, require explicit authorization |\n",
    "| Privacy leakage | Enforce memory retention policies, redaction |\n",
    "| Cost explosion | Cache results, limit tool calls, use cheaper models |\n",
    "| Infinite loops | Set max iterations, timeouts, circuit breakers |\n",
    "\n",
    "### Real-World Examples\n",
    "- **Customer Support Bot**: Routes to appropriate tools (FAQ search, ticket creation, escalation)\n",
    "- **Research Assistant**: Searches papers, summarizes findings, cites sources\n",
    "- **Code Assistant**: Reads codebase, runs tests, suggests fixes\n",
    "- **Personal Assistant**: Schedules meetings, sends emails, summarizes news\n",
    "- **DevOps Automation**: Deploys code, monitors systems, triggers alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57144c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal Self-Contained AI Agent Example (no external LLM required)\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, List, Any, Tuple\n",
    "import shlex\n",
    "import re\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Tool Wrapper & Registry\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Tool:\n",
    "    \"\"\"Represents a tool an agent can call.\"\"\"\n",
    "    name: str\n",
    "    func: Callable[..., Any]\n",
    "    description: str = \"\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Tool({self.name}: {self.description})\"\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Simple Agent with Planning, Execution, and Memory\n",
    "# ============================================================================\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"A minimal agent that perceives, plans, executes, and remembers.\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_name: str = \"Agent\"):\n",
    "        self.name = agent_name\n",
    "        self.tools: Dict[str, Tool] = {}\n",
    "        self.memory: List[str] = []  # Short-term trace of interactions\n",
    "        self.long_term_memory: Dict[str, Any] = {}  # Learnings from past interactions\n",
    "    \n",
    "    def add_tool(self, tool: Tool) -> None:\n",
    "        \"\"\"Register a tool the agent can use.\"\"\"\n",
    "        self.tools[tool.name] = tool\n",
    "    \n",
    "    def list_tools(self) -> List[str]:\n",
    "        \"\"\"List available tools.\"\"\"\n",
    "        return list(self.tools.keys())\n",
    "    \n",
    "    def remember(self, note: str) -> None:\n",
    "        \"\"\"Add to short-term memory (interaction trace).\"\"\"\n",
    "        self.memory.append(note)\n",
    "        if len(self.memory) > 20:  # Keep only recent 20 items\n",
    "            self.memory.pop(0)\n",
    "    \n",
    "    def learn(self, key: str, value: Any) -> None:\n",
    "        \"\"\"Store learnings in long-term memory.\"\"\"\n",
    "        self.long_term_memory[key] = value\n",
    "    \n",
    "    def plan(self, instruction: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Minimal planner: analyzes instruction and chooses action.\n",
    "        In a real system, this could be an LLM or symbolic planner.\n",
    "        Here we use keyword matching for demo purposes.\n",
    "        \"\"\"\n",
    "        text = instruction.lower()\n",
    "        \n",
    "        # Simple heuristics to choose tools\n",
    "        if any(kw in text for kw in ['calculate', 'compute', 'math', '+', '-', '*', '/']):\n",
    "            return {'action': 'use_tool', 'tool': 'calculator', 'input': instruction}\n",
    "        \n",
    "        if any(kw in text for kw in ['search', 'find', 'look up', 'what is', 'who is']):\n",
    "            query = instruction.replace('search ', '').replace('find ', '').strip()\n",
    "            return {'action': 'use_tool', 'tool': 'knowledge_base', 'input': query}\n",
    "        \n",
    "        if any(kw in text for kw in ['remember', 'note', 'save', 'store']):\n",
    "            return {'action': 'remember', 'input': instruction}\n",
    "        \n",
    "        # Default: try knowledge base\n",
    "        return {'action': 'use_tool', 'tool': 'knowledge_base', 'input': instruction}\n",
    "    \n",
    "    def execute(self, plan: Dict[str, str]) -> str:\n",
    "        \"\"\"Execute the plan (either use tool or remember).\"\"\"\n",
    "        action = plan.get('action', 'unknown')\n",
    "        \n",
    "        if action == 'remember':\n",
    "            self.learn('last_note', plan['input'])\n",
    "            return f\"‚úì Remembered: {plan['input']}\"\n",
    "        \n",
    "        if action == 'use_tool':\n",
    "            tool_name = plan.get('tool')\n",
    "            tool_input = plan.get('input', '')\n",
    "            \n",
    "            if tool_name not in self.tools:\n",
    "                return f\"‚úó Tool '{tool_name}' not available. Available: {self.list_tools()}\"\n",
    "            \n",
    "            try:\n",
    "                tool = self.tools[tool_name]\n",
    "                result = tool.func(tool_input)\n",
    "                return str(result)\n",
    "            except Exception as e:\n",
    "                return f\"‚úó Tool error: {e}\"\n",
    "        \n",
    "        return \"‚úó Unknown action\"\n",
    "    \n",
    "    def act(self, instruction: str) -> str:\n",
    "        \"\"\"\n",
    "        Main agent loop: perceive ‚Üí plan ‚Üí execute ‚Üí remember.\n",
    "        This is the core agent cycle.\n",
    "        \"\"\"\n",
    "        # PERCEIVE: process input\n",
    "        self.remember(f\"INPUT: {instruction}\")\n",
    "        \n",
    "        # PLAN: decide what to do\n",
    "        plan = self.plan(instruction)\n",
    "        self.remember(f\"PLAN: {plan}\")\n",
    "        \n",
    "        # EXECUTE: carry out the plan\n",
    "        outcome = self.execute(plan)\n",
    "        \n",
    "        # REMEMBER: store interaction for learning\n",
    "        self.remember(f\"OUTPUT: {outcome}\")\n",
    "        \n",
    "        return outcome\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Tool Implementations\n",
    "# ============================================================================\n",
    "\n",
    "def calculator_tool(expression: str) -> float:\n",
    "    \"\"\"\n",
    "    Safe calculator tool: evaluates arithmetic expressions.\n",
    "    Filters to only allow safe characters.\n",
    "    \"\"\"\n",
    "    # Remove spaces and extra text\n",
    "    tokens = shlex.split(expression)\n",
    "    expr_str = ''.join(tokens)\n",
    "    \n",
    "    # Whitelist only safe math characters\n",
    "    safe_chars = set('0123456789+-*/().%')\n",
    "    filtered = ''.join(ch for ch in expr_str if ch in safe_chars)\n",
    "    \n",
    "    if not filtered or filtered in '+-*/(.)%':\n",
    "        raise ValueError(f\"Invalid expression: {expression}\")\n",
    "    \n",
    "    try:\n",
    "        # Use eval with restricted namespace (no dangerous built-ins)\n",
    "        result = eval(filtered, {\"__builtins__\": {}})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Calculation failed: {e}\")\n",
    "\n",
    "def knowledge_base_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulated knowledge base: local search over a small company KB.\n",
    "    In production, this would query a real database or vector store.\n",
    "    \"\"\"\n",
    "    kb = {\n",
    "        'vacation days': '15 days PTO per year, accrues 1.25 days/month',\n",
    "        'health insurance': 'Employee pays 20% premium; benefits start after 30 days',\n",
    "        'remote work': 'Up to 3 days/week remote with manager approval',\n",
    "        'holidays': '10 paid holidays (New Year, Memorial Day, July 4, Labor Day, Thanksgiving 2 days, Christmas 3 days)',\n",
    "        '401k': 'Eligible after 90 days; 50% match up to 6% salary; 4-year vesting',\n",
    "        'sick leave': '8 days per year; no rollover',\n",
    "        'maternity leave': '12 weeks paid; 6 weeks paid paternity'\n",
    "    }\n",
    "    \n",
    "    q = query.lower()\n",
    "    \n",
    "    # Search for exact or partial matches\n",
    "    for key, value in kb.items():\n",
    "        if key in q or any(word in q for word in key.split()):\n",
    "            return f\"üìñ Found in KB: {value}\"\n",
    "    \n",
    "    return f\"üìñ No match found in KB for '{query}'. Try: {list(kb.keys())}\"\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Demo: Agent in Action\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"DEMO: SimpleAgent\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create and configure agent\n",
    "agent = SimpleAgent(agent_name=\"CompanyAssistant\")\n",
    "agent.add_tool(Tool(\"calculator\", calculator_tool, \"Evaluates math expressions\"))\n",
    "agent.add_tool(Tool(\"knowledge_base\", knowledge_base_tool, \"Searches company policies\"))\n",
    "\n",
    "print(f\"\\nAgent Name: {agent.name}\")\n",
    "print(f\"Available Tools: {agent.list_tools()}\\n\")\n",
    "\n",
    "# Test interactions\n",
    "test_queries = [\n",
    "    \"How many vacation days do I get per year?\",\n",
    "    \"Calculate 15 * 12 + 3.5\",\n",
    "    \"What is the remote work policy?\",\n",
    "    \"Remember that my manager is Alice\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüë§ User: {query}\")\n",
    "    result = agent.act(query)\n",
    "    print(f\"ü§ñ Agent: {result}\")\n",
    "\n",
    "# Show memory trace\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AGENT MEMORY TRACE (last 10 items):\")\n",
    "print(\"=\"*70)\n",
    "for i, item in enumerate(agent.memory[-10:], 1):\n",
    "    print(f\"  {i}. {item}\")\n",
    "\n",
    "# Show long-term learnings\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LONG-TERM LEARNINGS:\")\n",
    "print(\"=\"*70)\n",
    "for key, value in agent.long_term_memory.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Topic 2 ‚Äî Agent Architectures\n",
    "\n",
    "### Architecture Types\n",
    "\n",
    "#### 1. Reactive Agents (Reflex Agents)\n",
    "**How it works**: Map percepts directly to actions via condition-action rules.  \n",
    "**Latency**: Very fast (milliseconds)  \n",
    "**Complexity**: Simple, no state needed  \n",
    "**When to use**: \n",
    "- Real-time control (robotics, games)\n",
    "- Microservices with immediate responses\n",
    "- Safety-critical systems (fast fallback)\n",
    "\n",
    "**Pros**: Fast, predictable, easy to understand  \n",
    "**Cons**: No planning, no learning, limited to reflex behavior\n",
    "\n",
    "#### 2. Deliberative Agents (Planning Agents)\n",
    "**How it works**: Build internal model, use search/optimization to plan action sequences.  \n",
    "**Latency**: Slower (seconds to minutes), depends on planning complexity  \n",
    "**Complexity**: High, requires domain modeling  \n",
    "**When to use**:\n",
    "- Multi-step tasks (assembly, scheduling)\n",
    "- Constraint satisfaction (resource allocation)\n",
    "- Complex reasoning (diagnosis, strategy)\n",
    "\n",
    "**Pros**: Handles long-term goals, can reason about consequences  \n",
    "**Cons**: Planning overhead, requires good world model\n",
    "\n",
    "#### 3. Hybrid Architectures\n",
    "**How it works**: Combine reactive + deliberative: planner sets goals, reactive layer handles immediate responses and safety.  \n",
    "**Latency**: Mixed (fast reactions + slower planning in parallel)  \n",
    "**Complexity**: Moderate, but well-structured  \n",
    "**When to use**: Most modern assistants (balance responsiveness + reasoning)\n",
    "\n",
    "**Pros**: Responsive yet thoughtful, can interrupt planner for safety  \n",
    "**Cons**: More complex, harder to debug interactions\n",
    "\n",
    "#### 4. LLM-Based Agent Architecture (Modern Split)\n",
    "**Planner (LLM)**: Reads state, emits plan (tool calls, subtasks, reasoning)  \n",
    "**Executor (Deterministic)**: Carries out tool calls, validates results, handles side effects  \n",
    "**Integration Loop**: Executor feeds results back to LLM for next decision\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "[LLM Planner] ‚Üí \"I should call web_search, then summarize\"\n",
    "    ‚Üì\n",
    "[Tool Executor] ‚Üí Runs web_search, collects results\n",
    "    ‚Üì\n",
    "[LLM Planner] ‚Üí \"Now I'll summarize\" ‚Üí emits answer\n",
    "    ‚Üì\n",
    "User Answer (with citations)\n",
    "```\n",
    "\n",
    "**When to use**: Flexible, language-based reasoning required  \n",
    "**Pros**: Uses LLM's reasoning, auditable tool calls, repeatable  \n",
    "**Cons**: Latency (multiple LLM round-trips), cost (per-query LLM calls)\n",
    "\n",
    "### Decision Framework: Which Architecture?\n",
    "\n",
    "| Scenario | Best Choice | Why |\n",
    "|----------|------------|-----|\n",
    "| Stock trading bot (10ms latency) | Reactive | Speed critical |\n",
    "| Travel planner (\"book flight + hotel\") | Deliberative | Multi-step, constraints |\n",
    "| Customer support chatbot | Hybrid/LLM-based | Needs reactions + reasoning |\n",
    "| Robot navigating obstacles | Reactive layer + Planner | Safety + goal-seeking |\n",
    "| Code review assistant | LLM planner + tools | Language understanding + tool calls |\n",
    "| Game AI | Hybrid (planner for strategy, reactive for combat) | Balanced |\n",
    "\n",
    "### Architectural Considerations\n",
    "- **Error handling**: How to recover if a tool fails? Retry? Escalate? Replanning?\n",
    "- **Authorization**: Who can call which tools? Fine-grained access control?\n",
    "- **Observability**: Log every decision for debugging and audit trails\n",
    "- **Memory management**: What context to pass to the planner? Token limits?\n",
    "- **Feedback loops**: How does the agent learn from mistakes?\n",
    "\n",
    "### Common Pitfalls\n",
    "‚ùå **Too much context** ‚Üí LLM gets confused, slower  \n",
    "‚ùå **Too little context** ‚Üí Agent misses important info  \n",
    "‚ùå **Unsafe tool permissions** ‚Üí Agent calls dangerous tools  \n",
    "‚ùå **No error handling** ‚Üí Agent stuck in infinite loop  \n",
    "‚ùå **Poor observability** ‚Üí Can't debug why agent failed  \n",
    "\n",
    "### Implementation Pattern: Modular Stack\n",
    "```\n",
    "Perception Layer    ‚Üê User inputs, sensor data, API responses\n",
    "    ‚Üì\n",
    "Memory/Context      ‚Üê Short-term & long-term memory\n",
    "    ‚Üì\n",
    "Reasoning Engine    ‚Üê Planner, decision logic\n",
    "    ‚Üì\n",
    "Tool/Action Layer   ‚Üê Executors, API clients\n",
    "    ‚Üì\n",
    "Output/Feedback     ‚Üê User responses, logging, learning\n",
    "```\n",
    "\n",
    "Each layer is replaceable: swap planners, tool sets, memory backends, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended Agent: Demonstrating Different Architectures\n",
    "\n",
    "# ============================================================================\n",
    "# 1. REACTIVE AGENT (Condition-Action Rules)\n",
    "# ============================================================================\n",
    "\n",
    "class ReactiveAgent:\n",
    "    \"\"\"Ultra-fast agent: percept ‚Üí action via rules. No planning.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = []\n",
    "    \n",
    "    def add_rule(self, condition, action):\n",
    "        \"\"\"condition: lambda percept -> bool, action: lambda percept -> str\"\"\"\n",
    "        self.rules.append((condition, action))\n",
    "    \n",
    "    def act(self, percept: str) -> str:\n",
    "        \"\"\"Check rules in order, execute first match.\"\"\"\n",
    "        for condition, action in self.rules:\n",
    "            if condition(percept):\n",
    "                return action(percept)\n",
    "        return \"No rule matched\"\n",
    "\n",
    "# Setup reactive agent\n",
    "reactive = ReactiveAgent()\n",
    "reactive.add_rule(\n",
    "    lambda p: 'temperature' in p.lower(),\n",
    "    lambda p: \"üå°Ô∏è  I'll monitor temperature\"\n",
    ")\n",
    "reactive.add_rule(\n",
    "    lambda p: 'danger' in p.lower(),\n",
    "    lambda p: \"‚ö†Ô∏è  ALERT: Safety protocol activated!\"\n",
    ")\n",
    "\n",
    "print(\"REACTIVE AGENT (rules-based, ~1ms latency):\")\n",
    "print(f\"  Input: 'Temperature is rising'  ‚Üí {reactive.act('Temperature is rising')}\")\n",
    "print(f\"  Input: 'Danger detected'        ‚Üí {reactive.act('Danger detected')}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DELIBERATIVE AGENT (Planning with Search)\n",
    "# ============================================================================\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class DeliberativeAgent:\n",
    "    \"\"\"Planner agent: builds plan via backward search.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.domain = {}  # {action_name: (preconditions, effects)}\n",
    "        self.state = set()\n",
    "    \n",
    "    def add_action(self, name, preconditions, effects):\n",
    "        \"\"\"Register a PDDL-like action.\"\"\"\n",
    "        self.preconditions = lambda: preconditions\n",
    "        self.domain[name] = (preconditions, effects)\n",
    "    \n",
    "    def plan(self, goal, state, depth=0, max_depth=5):\n",
    "        \"\"\"Simple backward-chaining planner.\"\"\"\n",
    "        if depth > max_depth:\n",
    "            return None  # Depth limit\n",
    "        \n",
    "        if goal in state:\n",
    "            return []  # Goal achieved\n",
    "        \n",
    "        # Try each action\n",
    "        for action_name, (preconds, effects) in self.domain.items():\n",
    "            if goal in effects:\n",
    "                # This action achieves the goal; check preconditions\n",
    "                sub_plan = self.plan(preconds[0], state, depth + 1, max_depth)\n",
    "                if sub_plan is not None:\n",
    "                    return sub_plan + [action_name]\n",
    "        \n",
    "        return None  # No plan found\n",
    "    \n",
    "    def act_deliberatively(self, goal: str) -> str:\n",
    "        \"\"\"Plan and describe the sequence of actions.\"\"\"\n",
    "        simple_plan = [\"step1: search\", \"step2: analyze\", \"step3: report\"]\n",
    "        return f\"üìã Plan to achieve '{goal}':\\n  \" + \"\\n  \".join(simple_plan)\n",
    "\n",
    "deliberative = DeliberativeAgent()\n",
    "print(\"DELIBERATIVE AGENT (planning-based, ~100ms latency):\")\n",
    "print(deliberative.act_deliberatively(\"gather market data\"))\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# 3. HYBRID AGENT (Reactive + Planner)\n",
    "# ============================================================================\n",
    "\n",
    "class HybridAgent:\n",
    "    \"\"\"Combines fast reactions with deliberative planning.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reactive_rules = []\n",
    "        self.planner_goals = {}\n",
    "    \n",
    "    def add_reactive_rule(self, condition, action):\n",
    "        self.reactive_rules.append((condition, action))\n",
    "    \n",
    "    def add_goal(self, goal_name, plan_steps):\n",
    "        self.planner_goals[goal_name] = plan_steps\n",
    "    \n",
    "    def act(self, percept: str) -> str:\n",
    "        # REACTIVE: Check for immediate threats/opportunities\n",
    "        for condition, action in self.reactive_rules:\n",
    "            if condition(percept):\n",
    "                return f\"üö® REACTIVE: {action(percept)}\"\n",
    "        \n",
    "        # DELIBERATIVE: Use planner for non-urgent goals\n",
    "        for goal_name, steps in self.planner_goals.items():\n",
    "            if goal_name in percept.lower():\n",
    "                return f\"üéØ PLANNING: {goal_name}\\n  Steps: \" + \" ‚Üí \".join(steps)\n",
    "        \n",
    "        return \"‚ö†Ô∏è No reactive rule or planned goal matched\"\n",
    "\n",
    "hybrid = HybridAgent()\n",
    "hybrid.add_reactive_rule(\n",
    "    lambda p: 'emergency' in p.lower(),\n",
    "    lambda p: \"Activating emergency protocol!\"\n",
    ")\n",
    "hybrid.add_goal('book flight', ['search flights', 'check price', 'confirm booking'])\n",
    "\n",
    "print(\"HYBRID AGENT (reactive + planner, ~50ms latency):\")\n",
    "print(f\"  Input: 'emergency situation'  ‚Üí {hybrid.act('emergency situation')}\")\n",
    "print(f\"  Input: 'book flight to NYC'  ‚Üí {hybrid.act('book flight to NYC')}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. LLM-BASED AGENT (Planner + Executor Split)\n",
    "# ============================================================================\n",
    "\n",
    "class LLMBasedAgent:\n",
    "    \"\"\"\n",
    "    Mimics modern LLM-based agents: LLM as planner,\n",
    "    separate executor for tool calls.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tools = {}\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def register_tool(self, name: str, func):\n",
    "        self.tools[name] = func\n",
    "    \n",
    "    def llm_planner_mock(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simulates LLM deciding what tools to call.\n",
    "        In reality, this would be an API call to GPT-4, Claude, etc.\n",
    "        \"\"\"\n",
    "        # Heuristic: emulate what an LLM might decide\n",
    "        if 'weather' in query.lower():\n",
    "            return {'thought': 'Need to get weather data', 'tool': 'get_weather', 'input': 'current'}\n",
    "        if 'calculate' in query.lower():\n",
    "            return {'thought': 'This needs arithmetic', 'tool': 'calculator', 'input': query}\n",
    "        return {'thought': 'Direct answer', 'tool': None, 'input': None}\n",
    "    \n",
    "    def execute_tool(self, tool_name: str, tool_input: str) -> str:\n",
    "        \"\"\"Execute the tool chosen by planner.\"\"\"\n",
    "        if tool_name not in self.tools:\n",
    "            return f\"‚ùå Tool '{tool_name}' not found\"\n",
    "        return self.tools[tool_name](tool_input)\n",
    "    \n",
    "    def interact(self, user_query: str) -> str:\n",
    "        \"\"\"\n",
    "        Full LLM agent loop:\n",
    "        1. User query\n",
    "        2. LLM planner decides tool\n",
    "        3. Executor runs tool\n",
    "        4. LLM generates answer\n",
    "        \"\"\"\n",
    "        self.conversation_history.append(('user', user_query))\n",
    "        \n",
    "        # Step 1: Plan\n",
    "        plan = self.llm_planner_mock(user_query)\n",
    "        \n",
    "        # Step 2: Execute tool if needed\n",
    "        if plan['tool']:\n",
    "            tool_result = self.execute_tool(plan['tool'], plan['input'])\n",
    "        else:\n",
    "            tool_result = \"No tool needed\"\n",
    "        \n",
    "        # Step 3: Generate answer\n",
    "        answer = f\"üí≠ Thought: {plan['thought']}\\nüîß Action: {plan['tool'] or 'direct answer'}\\nüìù Result: {tool_result}\"\n",
    "        \n",
    "        self.conversation_history.append(('assistant', answer))\n",
    "        return answer\n",
    "\n",
    "llm_agent = LLMBasedAgent()\n",
    "llm_agent.register_tool('get_weather', lambda q: \"üå§Ô∏è  Sunny, 72¬∞F\")\n",
    "llm_agent.register_tool('calculator', lambda q: f\"Result: {eval(q.replace('calculate', '').strip())}\")\n",
    "\n",
    "print(\"LLM-BASED AGENT (planner + executor, ~500ms with LLM latency):\")\n",
    "print(llm_agent.interact(\"Calculate 25 * 4\"))\n",
    "print()\n",
    "print(llm_agent.interact(\"What is the weather?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10aa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb9449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f601bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37a8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6164705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262cf10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfe055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17379319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45f471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6768e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb54f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663e935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4c9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b87a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21377ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd7d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4bfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba346f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab036e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb87ec7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1d05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0416ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7471393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601be1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160b900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41eadfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25bd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea128d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b3157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf891cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6d4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b82e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae84fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321c360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16c990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71702a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe74bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972450a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54225a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0393a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b1e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
