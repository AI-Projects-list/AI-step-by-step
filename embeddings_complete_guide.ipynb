{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae7faa6",
   "metadata": {},
   "source": [
    "# Complete Embeddings Guide\n",
    "## All Embedding Techniques with Detailed Explanations, When/Why to Use, and Working Examples\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Table of Contents\n",
    "\n",
    "### **Part 1: Embedding Fundamentals**\n",
    "1. [What are Embeddings?](#1-what-are-embeddings)\n",
    "2. [Vector Spaces & Semantics](#2-vector-spaces)\n",
    "3. [Embedding Dimensions](#3-embedding-dimensions)\n",
    "4. [Distance Metrics (Cosine, Euclidean, Dot Product)](#4-distance-metrics)\n",
    "5. [Embedding Quality Evaluation](#5-embedding-quality)\n",
    "6. [Pre-trained vs Custom Embeddings](#6-pretrained-vs-custom)\n",
    "\n",
    "### **Part 2: Traditional Word Embeddings**\n",
    "7. [One-Hot Encoding](#7-one-hot)\n",
    "8. [TF-IDF Embeddings](#8-tfidf)\n",
    "9. [Word2Vec (Skip-gram)](#9-word2vec-skipgram)\n",
    "10. [Word2Vec (CBOW)](#10-word2vec-cbow)\n",
    "11. [GloVe (Global Vectors)](#11-glove)\n",
    "12. [FastText](#12-fasttext)\n",
    "\n",
    "### **Part 3: Contextualized Embeddings**\n",
    "13. [ELMo (Embeddings from Language Models)](#13-elmo)\n",
    "14. [BERT Embeddings](#14-bert)\n",
    "15. [RoBERTa Embeddings](#15-roberta)\n",
    "16. [DistilBERT Embeddings](#16-distilbert)\n",
    "17. [ALBERT Embeddings](#17-albert)\n",
    "18. [XLNet Embeddings](#18-xlnet)\n",
    "\n",
    "### **Part 4: Sentence & Document Embeddings**\n",
    "19. [Doc2Vec](#19-doc2vec)\n",
    "20. [Sentence-BERT (SBERT)](#20-sentence-bert)\n",
    "21. [Universal Sentence Encoder (USE)](#21-use)\n",
    "22. [InferSent](#22-infersent)\n",
    "23. [Sentence Transformers](#23-sentence-transformers)\n",
    "24. [SimCSE](#24-simcse)\n",
    "\n",
    "### **Part 5: Transformer-Based Embeddings**\n",
    "25. [GPT Embeddings](#25-gpt)\n",
    "26. [T5 Embeddings](#26-t5)\n",
    "27. [DeBERTa Embeddings](#27-deberta)\n",
    "28. [MPNet Embeddings](#28-mpnet)\n",
    "29. [MiniLM Embeddings](#29-minilm)\n",
    "\n",
    "### **Part 6: Multilingual Embeddings**\n",
    "30. [Multilingual BERT (mBERT)](#30-mbert)\n",
    "31. [XLM-RoBERTa](#31-xlm-roberta)\n",
    "32. [LaBSE (Language-agnostic BERT)](#32-labse)\n",
    "33. [LASER (Language-Agnostic SEntence Representations)](#33-laser)\n",
    "\n",
    "### **Part 7: Domain-Specific Embeddings**\n",
    "34. [BioBERT (Biomedical)](#34-biobert)\n",
    "35. [SciBERT (Scientific)](#35-scibert)\n",
    "36. [FinBERT (Financial)](#36-finbert)\n",
    "37. [Legal-BERT](#37-legalbert)\n",
    "38. [CodeBERT (Programming)](#38-codebert)\n",
    "\n",
    "### **Part 8: OpenAI & Commercial Embeddings**\n",
    "39. [OpenAI Embeddings (text-embedding-3-small)](#39-openai-small)\n",
    "40. [OpenAI Embeddings (text-embedding-3-large)](#40-openai-large)\n",
    "41. [Cohere Embeddings](#41-cohere)\n",
    "42. [Voyage AI Embeddings](#42-voyage)\n",
    "43. [Google Vertex AI Embeddings](#43-vertex)\n",
    "\n",
    "### **Part 9: Image Embeddings**\n",
    "44. [ResNet Embeddings](#44-resnet)\n",
    "45. [VGG Embeddings](#45-vgg)\n",
    "46. [CLIP (Contrastive Language-Image Pre-training)](#46-clip)\n",
    "47. [Vision Transformer (ViT)](#47-vit)\n",
    "48. [DINOv2](#48-dinov2)\n",
    "\n",
    "### **Part 10: Multimodal Embeddings**\n",
    "49. [CLIP (Text + Image)](#49-clip-multimodal)\n",
    "50. [ALIGN](#50-align)\n",
    "51. [ImageBind](#51-imagebind)\n",
    "52. [Flamingo](#52-flamingo)\n",
    "\n",
    "### **Part 11: Graph Embeddings**\n",
    "53. [Node2Vec](#53-node2vec)\n",
    "54. [DeepWalk](#54-deepwalk)\n",
    "55. [Graph Convolutional Networks (GCN)](#55-gcn)\n",
    "56. [GraphSAGE](#56-graphsage)\n",
    "\n",
    "### **Part 12: Specialized Embeddings**\n",
    "57. [Product Embeddings (E-commerce)](#57-product)\n",
    "58. [User Embeddings (Recommendation)](#58-user)\n",
    "59. [Knowledge Graph Embeddings (TransE)](#59-transe)\n",
    "60. [Audio Embeddings (Wav2Vec)](#60-wav2vec)\n",
    "61. [Video Embeddings (VideoMAE)](#61-videomae)\n",
    "\n",
    "### **Part 13: Embedding Operations**\n",
    "62. [Embedding Pooling (Mean, Max, CLS)](#62-pooling)\n",
    "63. [Embedding Concatenation](#63-concatenation)\n",
    "64. [Embedding Arithmetic (King - Man + Woman = Queen)](#64-arithmetic)\n",
    "65. [Embedding Normalization](#65-normalization)\n",
    "66. [Embedding Dimensionality Reduction (PCA, UMAP)](#66-dim-reduction)\n",
    "\n",
    "### **Part 14: Retrieval & Search**\n",
    "67. [Semantic Search](#67-semantic-search)\n",
    "68. [Dense Passage Retrieval (DPR)](#68-dpr)\n",
    "69. [ColBERT (Contextualized Late Interaction)](#69-colbert)\n",
    "70. [ANCE (Approximate Nearest Neighbor Negative Contrastive)](#70-ance)\n",
    "\n",
    "### **Part 15: Vector Databases**\n",
    "71. [Pinecone Integration](#71-pinecone)\n",
    "72. [Weaviate Integration](#72-weaviate)\n",
    "73. [Qdrant Integration](#73-qdrant)\n",
    "74. [Chroma Integration](#74-chroma)\n",
    "75. [FAISS (Facebook AI Similarity Search)](#75-faiss)\n",
    "\n",
    "### **Part 16: Fine-tuning & Training**\n",
    "76. [Fine-tuning Sentence Transformers](#76-finetune-st)\n",
    "77. [Contrastive Learning](#77-contrastive)\n",
    "78. [Triplet Loss Training](#78-triplet-loss)\n",
    "79. [Hard Negative Mining](#79-hard-negative)\n",
    "80. [Custom Embedding Models](#80-custom-models)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ How to Use This Guide\n",
    "\n",
    "Each embedding technique includes:\n",
    "- **ğŸ“– What**: Technique definition and purpose\n",
    "- **ğŸ¯ Why**: Advantages and use cases\n",
    "- **â±ï¸ When to Use**: Specific scenarios with examples\n",
    "- **âŒ When NOT to Use**: Limitations and alternatives\n",
    "- **ğŸ“Š How It Works**: Technical details and architecture\n",
    "- **ğŸ’» Complete Script Example**: Working code implementation\n",
    "- **ğŸŒ Real-World Applications**: Industry use cases\n",
    "- **ğŸ’¡ Key Insights**: Best practices and optimization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a65cf6",
   "metadata": {},
   "source": [
    "# 1. What are Embeddings?\n",
    "\n",
    "## ğŸ“– What are Embeddings?\n",
    "\n",
    "**Embeddings** are dense, continuous vector representations of data (text, images, audio, etc.) in a lower-dimensional space that capture semantic meaning and relationships.\n",
    "\n",
    "**Core Concept:**\n",
    "```\n",
    "Raw Data â†’ Embedding Model â†’ Dense Vector\n",
    "\n",
    "Example:\n",
    "\"cat\"     â†’ [0.2, -0.5, 0.8, ...]  (384 dimensions)\n",
    "\"dog\"     â†’ [0.3, -0.4, 0.7, ...]  (similar to cat)\n",
    "\"car\"     â†’ [-0.6, 0.2, -0.1, ...] (different from cat)\n",
    "```\n",
    "\n",
    "**Why Embeddings?**\n",
    "\n",
    "**Problem with Raw Text:**\n",
    "```python\n",
    "# Computers can't understand text directly\n",
    "\"The cat sat on the mat\"\n",
    "\"The dog sat on the rug\"\n",
    "\n",
    "# How similar are these? Hard to compute!\n",
    "```\n",
    "\n",
    "**Solution with Embeddings:**\n",
    "```python\n",
    "# Convert to vectors\n",
    "sentence1 = [0.2, 0.5, 0.8, ...]  # 384 dimensions\n",
    "sentence2 = [0.3, 0.6, 0.7, ...]  # 384 dimensions\n",
    "\n",
    "# Calculate similarity (cosine similarity)\n",
    "similarity = 0.92  # Very similar!\n",
    "```\n",
    "\n",
    "**Key Properties of Good Embeddings:**\n",
    "\n",
    "1. **Semantic Similarity**\n",
    "   - Similar meanings â†’ similar vectors\n",
    "   - \"happy\" is close to \"joyful\"\n",
    "   - \"cat\" is close to \"kitten\"\n",
    "\n",
    "2. **Dimensionality Reduction**\n",
    "   - Vocabulary: 50,000 words (sparse, one-hot)\n",
    "   - Embeddings: 384 dimensions (dense, meaningful)\n",
    "\n",
    "3. **Continuous Space**\n",
    "   - Smooth transitions between concepts\n",
    "   - \"cold\" â†’ \"cool\" â†’ \"warm\" â†’ \"hot\"\n",
    "\n",
    "4. **Compositionality**\n",
    "   - Can combine embeddings\n",
    "   - King - Man + Woman â‰ˆ Queen\n",
    "\n",
    "**Embedding Architecture:**\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           INPUT (Raw Data)                  â”‚\n",
    "â”‚  Text: \"Hello world\"                        â”‚\n",
    "â”‚  Image: 224x224 pixels                      â”‚\n",
    "â”‚  Audio: 16kHz waveform                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚       EMBEDDING MODEL                       â”‚\n",
    "â”‚  Neural Network (BERT, ResNet, etc.)        â”‚\n",
    "â”‚  - Tokenization                             â”‚\n",
    "â”‚  - Feature Extraction                       â”‚\n",
    "â”‚  - Dimensionality Reduction                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚       DENSE VECTOR (Embedding)              â”‚\n",
    "â”‚  [0.2, -0.5, 0.8, 0.1, -0.3, ...]           â”‚\n",
    "â”‚  Dimensions: 384, 768, 1024, 1536, etc.     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                 â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚       APPLICATIONS                          â”‚\n",
    "â”‚  - Semantic Search                          â”‚\n",
    "â”‚  - Similarity Comparison                    â”‚\n",
    "â”‚  - Clustering                               â”‚\n",
    "â”‚  - Classification                           â”‚\n",
    "â”‚  - Recommendation                           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ğŸ¯ Why Use Embeddings?\n",
    "\n",
    "### **Advantages:**\n",
    "1. **Semantic Understanding** - Capture meaning, not just words\n",
    "2. **Efficient Computation** - Dense vectors easier to process\n",
    "3. **Transfer Learning** - Pre-trained embeddings work across tasks\n",
    "4. **Similarity Search** - Fast nearest neighbor search\n",
    "5. **Dimensionality Reduction** - 50K vocab â†’ 384 dimensions\n",
    "6. **Context Awareness** - Modern embeddings capture context\n",
    "7. **Cross-modal** - Can embed text, images, audio in same space\n",
    "\n",
    "### **Problems Embeddings Solve:**\n",
    "1. **Sparse Representations** - One-hot encoding is inefficient\n",
    "2. **Semantic Gap** - \"car\" and \"automobile\" are different words but same meaning\n",
    "3. **High Dimensionality** - Vocabulary size makes computation expensive\n",
    "4. **No Similarity Measure** - Can't compare text directly\n",
    "5. **Context Loss** - Traditional methods ignore word context\n",
    "\n",
    "## â±ï¸ When to Use Embeddings\n",
    "\n",
    "### âœ… **Use Embeddings When:**\n",
    "\n",
    "**1. Semantic Search**\n",
    "- Example: Search \"python programming\" finds \"coding with python\"\n",
    "- Why: Embeddings capture meaning, not just keywords\n",
    "- Benefit: Better search results than exact match\n",
    "\n",
    "**2. Recommendation Systems**\n",
    "- Example: Netflix recommends similar movies\n",
    "- Why: Similar content has similar embeddings\n",
    "- Benefit: Discover related items users will like\n",
    "\n",
    "**3. Text Classification**\n",
    "- Example: Spam detection, sentiment analysis\n",
    "- Why: Embeddings as features for ML models\n",
    "- Benefit: Better accuracy than bag-of-words\n",
    "\n",
    "**4. Clustering & Topic Modeling**\n",
    "- Example: Group similar customer reviews\n",
    "- Why: Similar text clusters in embedding space\n",
    "- Benefit: Discover patterns automatically\n",
    "\n",
    "**5. Question Answering (QA)**\n",
    "- Example: ChatGPT, customer support bots\n",
    "- Why: Find relevant context for questions\n",
    "- Benefit: Retrieve accurate information\n",
    "\n",
    "**6. Duplicate Detection**\n",
    "- Example: Find duplicate questions on forums\n",
    "- Why: Duplicates have high embedding similarity\n",
    "- Benefit: Reduce redundancy\n",
    "\n",
    "**7. Retrieval-Augmented Generation (RAG)**\n",
    "- Example: AI assistant with knowledge base\n",
    "- Why: Retrieve relevant docs before generating answer\n",
    "- Benefit: Grounded, factual responses\n",
    "\n",
    "**8. Cross-lingual Tasks**\n",
    "- Example: Translate without parallel corpus\n",
    "- Why: Multilingual embeddings align languages\n",
    "- Benefit: Works across languages\n",
    "\n",
    "**9. Image Search**\n",
    "- Example: Google Images, Pinterest\n",
    "- Why: Visual similarity in embedding space\n",
    "- Benefit: Find similar images\n",
    "\n",
    "**10. Anomaly Detection**\n",
    "- Example: Detect unusual transactions\n",
    "- Why: Anomalies are far from normal embeddings\n",
    "- Benefit: Identify outliers\n",
    "\n",
    "### âŒ **Don't Use Embeddings When:**\n",
    "\n",
    "**1. Exact Keyword Match Needed**\n",
    "- Problem: Need to find exact product SKU \"XYZ-123\"\n",
    "- Better: Traditional database query\n",
    "- Why: Embeddings are for semantic similarity, not exact match\n",
    "\n",
    "**2. Very Small Dataset**\n",
    "- Problem: Only 10 documents to search\n",
    "- Better: Simple string matching\n",
    "- Why: Overhead not worth it for tiny data\n",
    "\n",
    "**3. Real-time Constraints (Microseconds)**\n",
    "- Problem: Sub-millisecond latency required\n",
    "- Better: Cached lookup tables\n",
    "- Why: Embedding computation adds latency\n",
    "\n",
    "**4. Structured Data Only**\n",
    "- Problem: Just numbers and categories\n",
    "- Better: Traditional ML features\n",
    "- Why: Embeddings designed for unstructured data\n",
    "\n",
    "**5. No Semantic Meaning**\n",
    "- Problem: Random IDs, hashes, codes\n",
    "- Better: Direct comparison\n",
    "- Why: No semantic relationships to capture\n",
    "\n",
    "## ğŸ“Š How It Works\n",
    "\n",
    "**Embedding Creation Process:**\n",
    "\n",
    "```\n",
    "Step 1: Tokenization\n",
    "  Input: \"The cat sat on the mat\"\n",
    "  Tokens: [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "  Token IDs: [101, 2054, 2938, 2006, 1996, 13523, 102]\n",
    "\n",
    "Step 2: Neural Network Processing\n",
    "  - Pass through embedding layer\n",
    "  - Transformer layers (BERT, GPT, etc.)\n",
    "  - Contextual representations\n",
    "\n",
    "Step 3: Pooling\n",
    "  - Mean pooling: Average all token embeddings\n",
    "  - Max pooling: Take maximum values\n",
    "  - CLS token: Use [CLS] token embedding\n",
    "\n",
    "Step 4: Output\n",
    "  Dense vector: [0.2, -0.5, 0.8, ..., 0.1]  (384 dimensions)\n",
    "```\n",
    "\n",
    "**Similarity Computation:**\n",
    "\n",
    "```python\n",
    "# Cosine Similarity (most common)\n",
    "similarity = (A Â· B) / (||A|| * ||B||)\n",
    "\n",
    "# Range: -1 (opposite) to 1 (identical)\n",
    "# 0.9+ = Very similar\n",
    "# 0.7-0.9 = Similar\n",
    "# 0.5-0.7 = Somewhat related\n",
    "# <0.5 = Different\n",
    "```\n",
    "\n",
    "## ğŸŒ Real-World Applications\n",
    "\n",
    "1. **Google Search** - Semantic search using BERT embeddings\n",
    "2. **Netflix/Spotify** - Content recommendation via embeddings\n",
    "3. **ChatGPT/Claude** - RAG with document embeddings\n",
    "4. **Pinterest** - Visual search with image embeddings\n",
    "5. **Grammarly** - Text similarity and style matching\n",
    "6. **Zillow** - Property recommendation with embeddings\n",
    "7. **Amazon** - Product search and recommendations\n",
    "8. **Twitter** - Tweet similarity and topic clustering\n",
    "9. **GitHub Copilot** - Code similarity and suggestions\n",
    "10. **Duolingo** - Language learning with multilingual embeddings\n",
    "\n",
    "## ğŸ’¡ Key Insights\n",
    "\n",
    "âœ… **Embeddings = Dense vectors capturing semantic meaning**  \n",
    "âœ… **Similar concepts â†’ similar vectors in embedding space**  \n",
    "âœ… **Typical dimensions: 384, 768, 1024, 1536**  \n",
    "âœ… **Cosine similarity** - Most common distance metric  \n",
    "âœ… **Pre-trained embeddings** - Use existing models (BERT, OpenAI)  \n",
    "âœ… **Context matters** - Modern embeddings consider surrounding words  \n",
    "âœ… **Transfer learning** - Embeddings work across tasks  \n",
    "âœ… **Vector databases** - Store and search embeddings efficiently  \n",
    "âœ… **Fine-tuning** - Adapt embeddings to your domain  \n",
    "âœ… **Multimodal** - Text, images, audio can share embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c27116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDINGS - COMPLETE EXAMPLE\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EMBEDDINGS - COMPREHENSIVE GUIDE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. WHAT ARE EMBEDDINGS? - BASIC CONCEPT\n",
    "print(\"\\n1. WHAT ARE EMBEDDINGS? - BASIC CONCEPT\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Simulate simple embeddings for demonstration\n",
    "# In reality, these would come from neural networks\n",
    "\n",
    "# Example: 5-dimensional embeddings (normally 384, 768, etc.)\n",
    "embeddings_dict = {\n",
    "    \"cat\": np.array([0.8, 0.7, 0.1, 0.2, 0.3]),\n",
    "    \"kitten\": np.array([0.75, 0.65, 0.15, 0.25, 0.35]),\n",
    "    \"dog\": np.array([0.7, 0.6, 0.2, 0.3, 0.4]),\n",
    "    \"puppy\": np.array([0.65, 0.55, 0.25, 0.35, 0.45]),\n",
    "    \"car\": np.array([0.1, 0.2, 0.8, 0.7, 0.6]),\n",
    "    \"vehicle\": np.array([0.15, 0.25, 0.75, 0.65, 0.55]),\n",
    "    \"apple\": np.array([0.3, 0.4, 0.5, 0.8, 0.2]),\n",
    "    \"orange\": np.array([0.35, 0.45, 0.45, 0.75, 0.25]),\n",
    "}\n",
    "\n",
    "print(\"Example Embeddings (5D vectors):\")\n",
    "for word, embedding in list(embeddings_dict.items())[:4]:\n",
    "    print(f\"  {word:10s}: {embedding}\")\n",
    "\n",
    "# 2. SEMANTIC SIMILARITY\n",
    "print(\"\\n2. SEMANTIC SIMILARITY (Cosine Similarity)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "def calculate_similarity(word1: str, word2: str, embeddings: dict) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two word embeddings\"\"\"\n",
    "    vec1 = embeddings[word1].reshape(1, -1)\n",
    "    vec2 = embeddings[word2].reshape(1, -1)\n",
    "    return cosine_similarity(vec1, vec2)[0][0]\n",
    "\n",
    "# Compare similar words\n",
    "print(\"\\nSimilarity between related words:\")\n",
    "pairs = [\n",
    "    (\"cat\", \"kitten\"),\n",
    "    (\"cat\", \"dog\"),\n",
    "    (\"dog\", \"puppy\"),\n",
    "    (\"car\", \"vehicle\"),\n",
    "]\n",
    "\n",
    "for word1, word2 in pairs:\n",
    "    sim = calculate_similarity(word1, word2, embeddings_dict)\n",
    "    print(f\"  {word1} â†” {word2}: {sim:.3f}\")\n",
    "\n",
    "# Compare unrelated words\n",
    "print(\"\\nSimilarity between unrelated words:\")\n",
    "unrelated_pairs = [\n",
    "    (\"cat\", \"car\"),\n",
    "    (\"dog\", \"apple\"),\n",
    "    (\"vehicle\", \"orange\"),\n",
    "]\n",
    "\n",
    "for word1, word2 in unrelated_pairs:\n",
    "    sim = calculate_similarity(word1, word2, embeddings_dict)\n",
    "    print(f\"  {word1} â†” {word2}: {sim:.3f}\")\n",
    "\n",
    "# 3. FIND MOST SIMILAR WORDS\n",
    "print(\"\\n3. FIND MOST SIMILAR WORDS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "def find_most_similar(query_word: str, embeddings: dict, top_k: int = 3) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Find top-k most similar words to query word\"\"\"\n",
    "    query_vec = embeddings[query_word]\n",
    "    similarities = []\n",
    "    \n",
    "    for word, vec in embeddings.items():\n",
    "        if word != query_word:  # Exclude the word itself\n",
    "            sim = cosine_similarity(query_vec.reshape(1, -1), vec.reshape(1, -1))[0][0]\n",
    "            similarities.append((word, sim))\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Test with different query words\n",
    "query_words = [\"cat\", \"car\", \"apple\"]\n",
    "\n",
    "for query in query_words:\n",
    "    print(f\"\\nMost similar to '{query}':\")\n",
    "    similar = find_most_similar(query, embeddings_dict, top_k=3)\n",
    "    for i, (word, sim) in enumerate(similar, 1):\n",
    "        print(f\"  {i}. {word:10s} (similarity: {sim:.3f})\")\n",
    "\n",
    "# 4. EMBEDDING ARITHMETIC\n",
    "print(\"\\n4. EMBEDDING ARITHMETIC (Compositionality)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Famous example: King - Man + Woman â‰ˆ Queen\n",
    "# Simplified: cat - kitten + puppy â‰ˆ dog\n",
    "\n",
    "def embedding_arithmetic(positive: List[str], negative: List[str], embeddings: dict) -> np.ndarray:\n",
    "    \"\"\"Perform embedding arithmetic: sum(positive) - sum(negative)\"\"\"\n",
    "    result = np.zeros_like(embeddings[list(embeddings.keys())[0]])\n",
    "    \n",
    "    for word in positive:\n",
    "        result += embeddings[word]\n",
    "    \n",
    "    for word in negative:\n",
    "        result -= embeddings[word]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def find_closest(target_vec: np.ndarray, embeddings: dict, exclude: List[str] = []) -> Tuple[str, float]:\n",
    "    \"\"\"Find closest word to target vector\"\"\"\n",
    "    best_word = None\n",
    "    best_sim = -1\n",
    "    \n",
    "    for word, vec in embeddings.items():\n",
    "        if word not in exclude:\n",
    "            sim = cosine_similarity(target_vec.reshape(1, -1), vec.reshape(1, -1))[0][0]\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_word = word\n",
    "    \n",
    "    return best_word, best_sim\n",
    "\n",
    "# Example: cat - kitten + puppy â‰ˆ ?\n",
    "print(\"\\nEmbedding Arithmetic: cat - kitten + puppy â‰ˆ ?\")\n",
    "result_vec = embedding_arithmetic(\n",
    "    positive=[\"cat\", \"puppy\"],\n",
    "    negative=[\"kitten\"],\n",
    "    embeddings=embeddings_dict\n",
    ")\n",
    "closest_word, similarity = find_closest(result_vec, embeddings_dict, exclude=[\"cat\", \"kitten\", \"puppy\"])\n",
    "print(f\"  Result: {closest_word} (similarity: {similarity:.3f})\")\n",
    "\n",
    "# Example: car - vehicle + cat â‰ˆ ?\n",
    "print(\"\\nEmbedding Arithmetic: car - vehicle + cat â‰ˆ ?\")\n",
    "result_vec = embedding_arithmetic(\n",
    "    positive=[\"car\", \"cat\"],\n",
    "    negative=[\"vehicle\"],\n",
    "    embeddings=embeddings_dict\n",
    ")\n",
    "closest_word, similarity = find_closest(result_vec, embeddings_dict, exclude=[\"car\", \"vehicle\", \"cat\"])\n",
    "print(f\"  Result: {closest_word} (similarity: {similarity:.3f})\")\n",
    "\n",
    "# 5. DIMENSIONALITY COMPARISON\n",
    "print(\"\\n5. DIMENSIONALITY COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# One-hot encoding (sparse)\n",
    "vocabulary = list(embeddings_dict.keys())\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "print(f\"\\nOne-Hot Encoding (Sparse):\")\n",
    "print(f\"  Vocabulary size: {vocab_size} words\")\n",
    "print(f\"  Vector dimension: {vocab_size}D (one per word)\")\n",
    "print(f\"  'cat' representation: [0,0,0,0,0,0,0,1] (mostly zeros)\")\n",
    "print(f\"  Memory: {vocab_size} values per word\")\n",
    "print(f\"  Similarity: Can't measure (orthogonal vectors)\")\n",
    "\n",
    "print(f\"\\nDense Embeddings:\")\n",
    "embedding_dim = embeddings_dict[\"cat\"].shape[0]\n",
    "print(f\"  Vocabulary size: {vocab_size} words\")\n",
    "print(f\"  Vector dimension: {embedding_dim}D (fixed, small)\")\n",
    "print(f\"  'cat' representation: {embeddings_dict['cat']}\")\n",
    "print(f\"  Memory: {embedding_dim} values per word\")\n",
    "print(f\"  Similarity: Easy to compute (cosine, dot product)\")\n",
    "print(f\"  Reduction: {vocab_size / embedding_dim:.1f}x smaller\")\n",
    "\n",
    "# 6. DISTANCE METRICS\n",
    "print(\"\\n6. DISTANCE METRICS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "def euclidean_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Euclidean distance\"\"\"\n",
    "    return np.linalg.norm(vec1 - vec2)\n",
    "\n",
    "def dot_product(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"Calculate dot product\"\"\"\n",
    "    return np.dot(vec1, vec2)\n",
    "\n",
    "word1, word2 = \"cat\", \"dog\"\n",
    "vec1, vec2 = embeddings_dict[word1], embeddings_dict[word2]\n",
    "\n",
    "print(f\"\\nComparing '{word1}' and '{word2}':\")\n",
    "print(f\"  Cosine Similarity: {calculate_similarity(word1, word2, embeddings_dict):.3f} (range: -1 to 1, higher=more similar)\")\n",
    "print(f\"  Euclidean Distance: {euclidean_distance(vec1, vec2):.3f} (range: 0 to âˆ, lower=more similar)\")\n",
    "print(f\"  Dot Product: {dot_product(vec1, vec2):.3f} (range: -âˆ to âˆ, higher=more similar)\")\n",
    "\n",
    "print(f\"\\nComparing '{word1}' and 'car' (unrelated):\")\n",
    "vec3 = embeddings_dict[\"car\"]\n",
    "print(f\"  Cosine Similarity: {calculate_similarity(word1, 'car', embeddings_dict):.3f}\")\n",
    "print(f\"  Euclidean Distance: {euclidean_distance(vec1, vec3):.3f}\")\n",
    "print(f\"  Dot Product: {dot_product(vec1, vec3):.3f}\")\n",
    "\n",
    "# 7. CLUSTERING WITH EMBEDDINGS\n",
    "print(\"\\n7. CLUSTERING WITH EMBEDDINGS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Stack all embeddings\n",
    "words = list(embeddings_dict.keys())\n",
    "X = np.array([embeddings_dict[word] for word in words])\n",
    "\n",
    "# Cluster into 3 groups\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Group words by cluster\n",
    "clustered_words = {}\n",
    "for word, cluster_id in zip(words, clusters):\n",
    "    if cluster_id not in clustered_words:\n",
    "        clustered_words[cluster_id] = []\n",
    "    clustered_words[cluster_id].append(word)\n",
    "\n",
    "print(\"\\nAutomatic clustering based on embeddings:\")\n",
    "for cluster_id, cluster_words in clustered_words.items():\n",
    "    print(f\"  Cluster {cluster_id + 1}: {', '.join(cluster_words)}\")\n",
    "\n",
    "# 8. PRACTICAL EXAMPLE: SEMANTIC SEARCH\n",
    "print(\"\\n8. PRACTICAL EXAMPLE: SEMANTIC SEARCH\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Simulate a document collection\n",
    "documents = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A dog chased a ball\",\n",
    "    \"I bought a new car yesterday\",\n",
    "    \"The kitten played with yarn\",\n",
    "    \"My vehicle needs an oil change\",\n",
    "]\n",
    "\n",
    "# Simple embedding: average word embeddings\n",
    "def get_document_embedding(text: str, embeddings: dict) -> np.ndarray:\n",
    "    \"\"\"Get document embedding by averaging word embeddings\"\"\"\n",
    "    words = text.lower().split()\n",
    "    vectors = [embeddings[word] for word in words if word in embeddings]\n",
    "    \n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros_like(embeddings[list(embeddings.keys())[0]])\n",
    "\n",
    "# Create document embeddings\n",
    "doc_embeddings = [get_document_embedding(doc, embeddings_dict) for doc in documents]\n",
    "\n",
    "# Search query\n",
    "query = \"pet animal\"\n",
    "query_embedding = get_document_embedding(query, embeddings_dict)\n",
    "\n",
    "print(f\"\\nSearch Query: '{query}'\")\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = []\n",
    "for i, doc_emb in enumerate(doc_embeddings):\n",
    "    sim = cosine_similarity(query_embedding.reshape(1, -1), doc_emb.reshape(1, -1))[0][0]\n",
    "    similarities.append((i, sim))\n",
    "\n",
    "# Sort by similarity\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nSearch Results (ranked by similarity):\")\n",
    "for rank, (doc_id, sim) in enumerate(similarities, 1):\n",
    "    print(f\"  {rank}. [{sim:.3f}] {documents[doc_id]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"âœ“ Embeddings = Dense vectors capturing semantic meaning\")\n",
    "print(\"âœ“ Similar concepts have similar embeddings (high cosine similarity)\")\n",
    "print(\"âœ“ Enable semantic search, clustering, classification, recommendation\")\n",
    "print(\"âœ“ Dimensionality reduction: 50K vocab â†’ 384-1536 dimensions\")\n",
    "print(\"âœ“ Compositionality: Can perform arithmetic (King - Man + Woman â‰ˆ Queen)\")\n",
    "print(\"âœ“ Distance metrics: Cosine similarity (most common), Euclidean, Dot product\")\n",
    "print(\"âœ“ Pre-trained models: BERT, OpenAI, Sentence Transformers\")\n",
    "print(\"âœ“ Applications: Search, RAG, recommendations, duplicate detection\")\n",
    "print(\"âœ“ Vector databases: FAISS, Pinecone, Weaviate, Qdrant, Chroma\")\n",
    "print(\"âœ“ Modern embeddings are contextual (same word, different context = different embedding)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a53eba",
   "metadata": {},
   "source": [
    "# 2. Vector Spaces & Semantics\n",
    "\n",
    "## ğŸ“– What are Vector Spaces in Embeddings?\n",
    "\n",
    "**Vector Space** is the mathematical framework where embeddings exist. Each dimension represents a learned feature, and positions in this space encode semantic relationships.\n",
    "\n",
    "**Core Concept:**\n",
    "```\n",
    "High-Dimensional Space (e.g., 384 dimensions)\n",
    "- Each word/sentence/document is a point\n",
    "- Distance between points = semantic similarity\n",
    "- Clusters form around related concepts\n",
    "\n",
    "Example in 2D (simplified):\n",
    "       Pets\n",
    "        â†‘\n",
    "   dog  â€¢  cat\n",
    "        |\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â†’ Vehicles\n",
    "        |\n",
    "    car â€¢ vehicle\n",
    "        â†“\n",
    "```\n",
    "\n",
    "**Vector Space Properties:**\n",
    "\n",
    "1. **Continuous Space**\n",
    "   - Smooth transitions between concepts\n",
    "   - No discrete boundaries\n",
    "   - Example: \"cold\" gradually transitions to \"hot\"\n",
    "\n",
    "2. **Semantic Neighborhoods**\n",
    "   - Related words cluster together\n",
    "   - \"happy\", \"joyful\", \"delighted\" form a cluster\n",
    "   - \"sad\", \"unhappy\", \"depressed\" form another cluster\n",
    "\n",
    "3. **Geometric Relationships**\n",
    "   - Angles represent similarity\n",
    "   - Parallel vectors = similar meaning\n",
    "   - Orthogonal vectors = unrelated meaning\n",
    "\n",
    "4. **Subspaces for Concepts**\n",
    "   - Gender: \"king\" - \"man\" + \"woman\" = \"queen\"\n",
    "   - Tense: \"walk\" - \"walking\" + \"swimming\" = \"swim\"\n",
    "   - Country-Capital: \"Paris\" - \"France\" + \"Germany\" = \"Berlin\"\n",
    "\n",
    "**How Semantics are Encoded:**\n",
    "\n",
    "```\n",
    "Learned Dimensions (examples):\n",
    "- Dimension 1: Animal vs Non-animal (0.9 for \"cat\", 0.1 for \"car\")\n",
    "- Dimension 2: Sentiment (0.8 for \"happy\", -0.8 for \"sad\")\n",
    "- Dimension 3: Size (0.9 for \"large\", -0.9 for \"tiny\")\n",
    "- Dimension 4: Abstract vs Concrete (0.9 for \"love\", -0.9 for \"rock\")\n",
    "- ... (380 more dimensions for 384D embeddings)\n",
    "\n",
    "Note: Real dimensions are learned automatically,\n",
    "      not manually defined like above.\n",
    "```\n",
    "\n",
    "## ğŸ¯ Why Vector Spaces Matter\n",
    "\n",
    "### **Advantages:**\n",
    "1. **Mathematical Operations** - Can use linear algebra\n",
    "2. **Similarity Computation** - Fast distance calculations\n",
    "3. **Interpolation** - Smooth transitions between concepts\n",
    "4. **Compositionality** - Combine embeddings meaningfully\n",
    "5. **Dimensionality Reduction** - Visualize in 2D/3D\n",
    "6. **Clustering** - Group similar items automatically\n",
    "7. **Generalization** - New words positioned based on context\n",
    "\n",
    "### **Key Insights:**\n",
    "- **Distributional Hypothesis**: \"Words appearing in similar contexts have similar meanings\"\n",
    "- **Semantic Space**: Captures relationships learned from massive text corpora\n",
    "- **Transfer Learning**: Pre-trained spaces work across tasks\n",
    "\n",
    "## â±ï¸ When to Consider Vector Space Properties\n",
    "\n",
    "### âœ… **Important When:**\n",
    "\n",
    "**1. Semantic Search**\n",
    "- Why: Need to find semantically similar items\n",
    "- How: Query embedding finds nearest neighbors in space\n",
    "- Benefit: Retrieves relevant results beyond keyword match\n",
    "\n",
    "**2. Analogy Tasks**\n",
    "- Why: Relationships encoded as vector offsets\n",
    "- How: \"A is to B as C is to ?\" â†’ vec(B) - vec(A) + vec(C)\n",
    "- Benefit: Discover relationships automatically\n",
    "\n",
    "**3. Clustering**\n",
    "- Why: Similar items cluster in vector space\n",
    "- How: K-means, DBSCAN on embeddings\n",
    "- Benefit: Automatic categorization\n",
    "\n",
    "**4. Interpolation**\n",
    "- Why: Generate intermediate concepts\n",
    "- How: Linear interpolation between embeddings\n",
    "- Benefit: Explore semantic gradients\n",
    "\n",
    "**5. Visualization**\n",
    "- Why: Understand model behavior\n",
    "- How: Reduce to 2D/3D (t-SNE, UMAP)\n",
    "- Benefit: Discover patterns, debug issues\n",
    "\n",
    "### âŒ **Less Important When:**\n",
    "\n",
    "**1. Exact Matching Only**\n",
    "- Problem: Just need exact string match\n",
    "- Better: String comparison\n",
    "- Why: No need for semantic space\n",
    "\n",
    "**2. Small Vocabulary**\n",
    "- Problem: Only 10 unique items\n",
    "- Better: Simple lookup table\n",
    "- Why: Overhead not justified\n",
    "\n",
    "## ğŸ’¡ Key Insights\n",
    "\n",
    "âœ… **Vector space = high-dimensional semantic map**  \n",
    "âœ… **Distance = similarity** (closer = more similar)  \n",
    "âœ… **Directions encode relationships** (gender, tense, etc.)  \n",
    "âœ… **Clusters form naturally** around related concepts  \n",
    "âœ… **Dimensionality**: More dimensions = richer semantics  \n",
    "âœ… **Learned automatically** from data, not hand-crafted  \n",
    "âœ… **Transfer across tasks** - same space, different uses  \n",
    "âœ… **Visualization**: t-SNE, UMAP for 2D/3D projections  \n",
    "âœ… **Continuous**: Smooth interpolation between concepts  \n",
    "âœ… **Composable**: Combine embeddings with arithmetic"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
